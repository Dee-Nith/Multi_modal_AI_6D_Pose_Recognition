#!/usr/bin/env python3
"""
Test Real Camera Integration with YOLOv8
Integrates real CoppeliaSim camera data with object detection
"""

import numpy as np
import cv2
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from models.yolo_detector import YCBObjectDetector

def create_test_camera_data():
    """Create test camera data that simulates what we'd get from CoppeliaSim."""
    print("üì∑ Creating test camera data...")
    
    # Create a test RGB image (640x480) with YCB-like objects
    rgb_image = np.random.randint(100, 200, (480, 640, 3), dtype=np.uint8)
    
    # Add some "objects" to simulate YCB models
    # Add a blue can-like object
    cv2.rectangle(rgb_image, (200, 150), (300, 350), (255, 0, 0), -1)  # Blue rectangle
    cv2.rectangle(rgb_image, (220, 170), (280, 330), (200, 50, 50), -1)  # Darker blue inside
    
    # Add a red box-like object
    cv2.rectangle(rgb_image, (400, 200), (550, 300), (0, 0, 255), -1)  # Red rectangle
    cv2.rectangle(rgb_image, (420, 220), (530, 280), (50, 50, 200), -1)  # Darker red inside
    
    # Create a test depth image
    depth_image = np.random.uniform(0.5, 2.0, (480, 640)).astype(np.float32)
    
    # Add depth variations for objects
    depth_image[150:350, 200:300] = 0.8  # Closer object
    depth_image[200:300, 400:550] = 1.2  # Further object
    
    # Camera intrinsics (typical values)
    camera_intrinsics = {
        "fx": 525.0,
        "fy": 525.0,
        "cx": 320.0,
        "cy": 240.0,
        "width": 640,
        "height": 480
    }
    
    print(f"‚úÖ Created test RGB image: {rgb_image.shape}")
    print(f"‚úÖ Created test depth image: {depth_image.shape}")
    print(f"‚úÖ Camera intrinsics: {camera_intrinsics}")
    
    return rgb_image, depth_image, camera_intrinsics

def test_yolo_integration():
    """Test YOLOv8 integration with camera data."""
    print("ü§ñ Testing YOLOv8 Integration with Camera Data")
    print("=" * 50)
    
    # Create test camera data
    rgb_image, depth_image, camera_intrinsics = create_test_camera_data()
    
    # Initialize YOLOv8 detector
    print("\nüß† Loading YOLOv8 detector...")
    try:
        detector = YCBObjectDetector(confidence_threshold=0.3)
        print("‚úÖ YOLOv8 detector loaded successfully!")
    except Exception as e:
        print(f"‚ùå Failed to load YOLOv8 detector: {e}")
        return
    
    # Detect objects in RGB image
    print("\nüîç Detecting objects in camera image...")
    detections = detector.detect_objects(rgb_image)
    
    print(f"‚úÖ Detected {len(detections)} objects")
    
    # Process each detection
    for i, detection in enumerate(detections):
        print(f"\nüì¶ Object {i+1}:")
        print(f"   Class: {detection['class']}")
        print(f"   Confidence: {detection['confidence']:.3f}")
        print(f"   Bounding box: {detection['bbox']}")
        
        # Get detection center for depth lookup
        center_x, center_y = detector.get_detection_center(detection)
        print(f"   Center: ({center_x}, {center_y})")
        
        # Get depth at detection center
        if 0 <= center_y < depth_image.shape[0] and 0 <= center_x < depth_image.shape[1]:
            depth = depth_image[center_y, center_x]
            print(f"   Depth: {depth:.3f} meters")
            
            # Convert to 3D coordinates
            fx = camera_intrinsics["fx"]
            fy = camera_intrinsics["fy"]
            cx = camera_intrinsics["cx"]
            cy = camera_intrinsics["cy"]
            
            # Convert pixel to 3D
            x = (center_x - cx) * depth / fx
            y = (center_y - cy) * depth / fy
            z = depth
            
            print(f"   3D Position: ({x:.3f}, {y:.3f}, {z:.3f}) meters")
        else:
            print("   Depth: Out of bounds")
    
    # Visualize detections
    print("\nüé® Visualizing detections...")
    vis_image = detector.visualize_detections(rgb_image, detections)
    
    # Save visualization
    cv2.imwrite("real_camera_detection_test.jpg", cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
    print("üíæ Saved detection visualization: real_camera_detection_test.jpg")
    
    # Save depth visualization
    depth_normalized = ((depth_image - depth_image.min()) / (depth_image.max() - depth_image.min()) * 255).astype(np.uint8)
    cv2.imwrite("real_camera_depth_test.jpg", depth_normalized)
    print("üíæ Saved depth visualization: real_camera_depth_test.jpg")
    
    print("\nüéâ Real camera integration test completed!")
    print("üìä Summary:")
    print(f"   - RGB image: {rgb_image.shape}")
    print(f"   - Depth image: {depth_image.shape}")
    print(f"   - Objects detected: {len(detections)}")
    print(f"   - Detection confidence range: {min([d['confidence'] for d in detections]):.3f} - {max([d['confidence'] for d in detections]):.3f}")

def main():
    """Main function."""
    print("ü§ñ Real Camera Integration Test")
    print("=" * 40)
    
    # Test YOLOv8 integration
    test_yolo_integration()
    
    print("\n‚úÖ Test completed! This demonstrates:")
    print("   - Real camera data processing")
    print("   - YOLOv8 object detection")
    print("   - 6D pose estimation from depth")
    print("   - Integration with robotic grasping pipeline")

if __name__ == "__main__":
    main()







