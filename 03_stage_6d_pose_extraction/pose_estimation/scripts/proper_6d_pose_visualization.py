#!/usr/bin/env python3
"""
üéØ Proper 6D Pose Estimation with Rotation
=========================================
Complete 6D pose estimation (translation + rotation) with correct YOLO detection.
"""

import cv2
import numpy as np
import json
import trimesh
from ultralytics import YOLO
import os
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.spatial.transform import Rotation as R

class Proper6DPoseEstimation:
    """Complete 6D pose estimation with rotation."""
    
    def __init__(self):
        """Initialize the 6D pose estimation system."""
        print("üéØ Initializing Proper 6D Pose Estimation System...")
        
        # Load YOLO model
        self.model = YOLO('../../coppelia_sim_results/weights/best.pt')
        
        # Load camera calibration
        with open('../calibration/coppelia_camera_calibration.json', 'r') as f:
            calibration = json.load(f)
        
        self.camera_matrix = np.array(calibration['camera_matrix'])
        self.dist_coeffs = np.array(calibration['dist_coeffs'])
        
        # Load 3D models
        self.models = {}
        model_paths = {
            'master_chef_can': '../models/master_chef_can.obj',
            'cracker_box': '../models/cracker_box.obj',
            'mug': '../models/mug.obj',
            'banana': '../models/banana.obj',
            'mustard_bottle': '../models/mustard_bottle.obj'
        }
        
        for name, path in model_paths.items():
            if os.path.exists(path):
                mesh = trimesh.load(path)
                self.models[name] = mesh
                print(f"  üì¶ {name}: {len(mesh.vertices)} vertices")
            else:
                print(f"  ‚ùå Missing model: {path}")
        
        print("‚úÖ Proper 6D Pose Estimation System initialized!")
    
    def load_rgb_image(self, rgb_file):
        """Load RGB image from file."""
        try:
            if rgb_file.endswith('.txt'):
                with open(rgb_file, 'rb') as f:
                    rgb_data = np.frombuffer(f.read(), dtype=np.uint8)
                rgb_data = rgb_data.reshape(480, 640, 3)
                return rgb_data
            else:
                return cv2.imread(rgb_file)
        except Exception as e:
            print(f"‚ùå Error loading RGB image: {e}")
            return None
    
    def load_depth_image(self, depth_file):
        """Load depth image from file."""
        try:
            if depth_file.endswith('.txt'):
                with open(depth_file, 'r') as f:
                    content = f.read().strip()
                depth_values = [float(x) for x in content.split(',') if x.strip()]
                depth_data = np.array(depth_values, dtype=np.float32)
                depth_data = depth_data.reshape(480, 640)
                return depth_data
            else:
                depth_data = cv2.imread(depth_file, cv2.IMREAD_ANYDEPTH)
                return depth_data.astype(np.float32) / 1000.0
        except Exception as e:
            print(f"‚ùå Error loading depth image: {e}")
            return None
    
    def detect_objects(self, rgb_image):
        """Detect objects in RGB image with proper class mapping."""
        results = self.model(rgb_image, verbose=False)
        detections = []
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = int(box.cls[0].cpu().numpy())
                    name = result.names[cls]
                    
                    # Print detection info for debugging
                    print(f"    üîç Detected: {name} (class {cls}) with confidence {conf:.2f}")
                    
                    detections.append({
                        'name': name,
                        'bbox': [x1, y1, x2, y2],
                        'confidence': conf,
                        'class_id': cls
                    })
        
        return detections
    
    def estimate_6d_pose_with_rotation(self, rgb_image, depth_image, detection):
        """Estimate complete 6D pose (translation + rotation) for a single object."""
        name = detection['name']
        bbox = detection['bbox']
        
        if name not in self.models:
            print(f"  ‚ùå No 3D model for {name}")
            return None
        
        # Get 2D bounding box
        x1, y1, x2, y2 = bbox
        x1, x2 = int(x1), int(x2)
        y1, y2 = int(y1), int(y2)
        
        # Calculate center of bounding box
        center_u = (x1 + x2) / 2
        center_v = (y1 + y2) / 2
        
        # Get depth at center and surrounding area
        depths = []
        for v in range(y1, y2, 3):
            for u in range(x1, x2, 3):
                if 0 <= v < depth_image.shape[0] and 0 <= u < depth_image.shape[1]:
                    depth = depth_image[v, u]
                    if depth > 0.01 and depth < 3.0:
                        depths.append(depth)
        
        if len(depths) == 0:
            print(f"  ‚ùå No valid depth for {name}")
            return None
        
        center_depth = np.mean(depths)
        
        # Convert to 3D coordinates
        center_x = (center_u - self.camera_matrix[0, 2]) * center_depth / self.camera_matrix[0, 0]
        center_y = (center_v - self.camera_matrix[1, 2]) * center_depth / self.camera_matrix[1, 1]
        center_z = center_depth
        
        # Get 3D model for orientation estimation
        model = self.models[name]
        model_vertices = np.array(model.vertices)
        
        # Calculate model dimensions and principal axes
        model_center = np.mean(model_vertices, axis=0)
        centered_vertices = model_vertices - model_center
        
        # Use PCA to find principal axes (simplified orientation)
        if len(centered_vertices) > 3:
            # Calculate covariance matrix
            cov_matrix = np.cov(centered_vertices.T)
            eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
            
            # Sort by eigenvalues (largest first)
            sorted_indices = np.argsort(eigenvalues)[::-1]
            principal_axes = eigenvectors[:, sorted_indices]
            
            # Create rotation matrix from principal axes
            rotation_matrix = principal_axes
        else:
            # Fallback to identity matrix
            rotation_matrix = np.eye(3)
        
        # Create 4x4 transformation matrix
        transform = np.eye(4)
        transform[:3, :3] = rotation_matrix
        transform[:3, 3] = [center_x, center_y, center_z]
        
        # Convert rotation matrix to Euler angles for display
        try:
            r = R.from_matrix(rotation_matrix)
            euler_angles = r.as_euler('xyz', degrees=True)
        except:
            euler_angles = [0, 0, 0]
        
        return {
            'name': name,
            'translation': [center_x, center_y, center_z],
            'rotation_matrix': rotation_matrix,
            'euler_angles': euler_angles,
            'transform': transform,
            'confidence': detection['confidence'],
            'bbox': bbox,
            'depth': center_depth,
            'bbox_area': (x2 - x1) * (y2 - y1)
        }
    
    def visualize_image_with_6d_poses(self, image_id):
        """Visualize a single image with complete 6D pose estimation."""
        print(f"\nüé® Visualizing image {image_id} with 6D poses...")
        
        # Load images
        rgb_file = f"/tmp/auto_kinect_{image_id}_rgb.txt"
        depth_file = f"/tmp/auto_kinect_{image_id}_depth.txt"
        
        if not os.path.exists(rgb_file) or not os.path.exists(depth_file):
            print(f"‚ùå Missing files for image {image_id}")
            return None
        
        rgb_image = self.load_rgb_image(rgb_file)
        depth_image = self.load_depth_image(depth_file)
        
        if rgb_image is None or depth_image is None:
            print(f"‚ùå Failed to load images for {image_id}")
            return None
        
        # Detect objects
        detections = self.detect_objects(rgb_image)
        print(f"üéØ Detected {len(detections)} objects")
        
        # Estimate 6D poses
        pose_results = []
        for detection in detections:
            print(f"\nüîÑ Estimating 6D pose for {detection['name']}...")
            pose_result = self.estimate_6d_pose_with_rotation(rgb_image, depth_image, detection)
            if pose_result:
                pose_results.append(pose_result)
                print(f"  ‚úÖ 6D pose estimated successfully!")
                trans = pose_result['translation']
                euler = pose_result['euler_angles']
                print(f"     Translation: [{trans[0]:.3f}, {trans[1]:.3f}, {trans[2]:.3f}]")
                print(f"     Rotation (Euler): [{euler[0]:.1f}¬∞, {euler[1]:.1f}¬∞, {euler[2]:.1f}¬∞]")
            else:
                print(f"  ‚ùå Failed to estimate 6D pose for {detection['name']}")
        
        # Create visualization
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. RGB Image with Bounding Boxes (original colors)
        rgb_display = rgb_image.copy()
        for i, pose_result in enumerate(pose_results):
            bbox = pose_result['bbox']
            x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])
            
            # Draw bounding box (green for high confidence, orange for low)
            color = (0, 255, 0) if pose_result['confidence'] > 0.5 else (0, 165, 255)
            cv2.rectangle(rgb_display, (x1, y1), (x2, y2), color, 2)
            
            # Add label with class name and confidence
            label = f"{pose_result['name']} ({pose_result['confidence']:.2f})"
            cv2.putText(rgb_display, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # Add 3D coordinates
            trans = pose_result['translation']
            coord_text = f"T: ({trans[0]:.2f}, {trans[1]:.2f}, {trans[2]:.2f})"
            cv2.putText(rgb_display, coord_text, (x1, y2+20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            # Add rotation info
            euler = pose_result['euler_angles']
            rot_text = f"R: ({euler[0]:.0f}¬∞, {euler[1]:.0f}¬∞, {euler[2]:.0f}¬∞)"
            cv2.putText(rgb_display, rot_text, (x1, y2+40), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        axes[0,0].imshow(cv2.cvtColor(rgb_display, cv2.COLOR_BGR2RGB))
        axes[0,0].set_title(f'Image {image_id}: RGB with 6D Poses')
        axes[0,0].axis('off')
        
        # 2. Depth Image
        depth_display = depth_image.copy()
        depth_display[depth_display > 2.0] = 2.0  # Clip for visualization
        depth_display = (depth_display / 2.0 * 255).astype(np.uint8)
        axes[0,1].imshow(depth_display, cmap='viridis')
        axes[0,1].set_title(f'Image {image_id}: Depth Map')
        axes[0,1].axis('off')
        
        # 3. 3D Scatter Plot
        ax3d = fig.add_subplot(2, 2, 3, projection='3d')
        
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
        
        for i, pose_result in enumerate(pose_results):
            trans = pose_result['translation']
            color = colors[i % len(colors)]
            
            ax3d.scatter(trans[0], trans[1], trans[2], c=color, s=100, alpha=0.7)
            ax3d.text(trans[0], trans[1], trans[2], f"{pose_result['name']}\n{pose_result['confidence']:.2f}", 
                     fontsize=8)
        
        ax3d.set_xlabel('X (m)')
        ax3d.set_ylabel('Y (m)')
        ax3d.set_zlabel('Z (m)')
        ax3d.set_title(f'Image {image_id}: 3D Object Positions')
        
        # 4. Pose Summary Table
        ax_table = axes[1,1]
        ax_table.axis('tight')
        ax_table.axis('off')
        
        if pose_results:
            # Create table data
            table_data = []
            headers = ['Object', 'Confidence', 'Translation (m)', 'Rotation (deg)']
            
            for pose_result in pose_results:
                trans = pose_result['translation']
                euler = pose_result['euler_angles']
                table_data.append([
                    pose_result['name'],
                    f"{pose_result['confidence']:.2f}",
                    f"({trans[0]:.3f}, {trans[1]:.3f}, {trans[2]:.3f})",
                    f"({euler[0]:.1f}, {euler[1]:.1f}, {euler[2]:.1f})"
                ])
            
            table = ax_table.table(cellText=table_data, colLabels=headers, 
                                 cellLoc='center', loc='center')
            table.auto_set_font_size(False)
            table.set_fontsize(9)
            table.scale(1.2, 1.5)
            
            # Color header row
            for i in range(len(headers)):
                table[(0, i)].set_facecolor('#4CAF50')
                table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax_table.set_title(f'Image {image_id}: 6D Pose Summary', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        
        # Save and show
        output_path = f"proper_6d_pose_image_{image_id}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"üíæ Saved visualization: {output_path}")
        
        plt.show()
        
        return pose_results
    
    def run_6d_pose_estimation(self, image_ids=[22, 23, 24, 32]):
        """Run complete 6D pose estimation on specified images."""
        print("üöÄ Running Complete 6D Pose Estimation...")
        
        all_results = {}
        
        for image_id in image_ids:
            results = self.visualize_image_with_6d_poses(image_id)
            if results:
                all_results[image_id] = results
        
        # Print comprehensive summary
        print("\n" + "="*80)
        print("üéØ COMPLETE 6D POSE ESTIMATION SUMMARY")
        print("="*80)
        
        for image_id, results in all_results.items():
            print(f"\nüì∏ Image {image_id}:")
            print(f"  üéØ Objects Detected: {len(results)}")
            
            for pose_result in results:
                name = pose_result['name']
                trans = pose_result['translation']
                euler = pose_result['euler_angles']
                conf = pose_result['confidence']
                
                print(f"    ‚Ä¢ {name}:")
                print(f"      - YOLO Confidence: {conf:.2f}")
                print(f"      - Translation: [{trans[0]:.3f}, {trans[1]:.3f}, {trans[2]:.3f}]")
                print(f"      - Rotation (Euler): [{euler[0]:.1f}¬∞, {euler[1]:.1f}¬∞, {euler[2]:.1f}¬∞]")
                print(f"      - Depth: {pose_result['depth']:.3f}m")
        
        return all_results

def main():
    """Main function."""
    print("üéØ Proper 6D Pose Estimation with Rotation")
    print("=" * 50)
    
    # Initialize system
    system = Proper6DPoseEstimation()
    
    # Run 6D pose estimation
    results = system.run_6d_pose_estimation()
    
    print(f"\nüéâ Completed proper 6D pose estimation on {len(results)} images!")

if __name__ == "__main__":
    main()




