# ğŸ¤– Multi-Modal AI 6D Pose Recognition System

## ğŸ¯ Project Overview

This project presents a **complete robotic manipulation system** that achieves **real-time 6D pose estimation** with **millimeter-level precision**. The system successfully resolves the critical trade-off between speed and accuracy in industrial robotics applications.

## ğŸ“Š Key Performance Metrics

- **âš¡ Real-Time Processing**: 49.2ms (20.3 FPS)
- **ğŸ¯ High Accuracy**: Â±2mm position, Â±0.1Â° orientation
- **ğŸ” Detection Rate**: 100% with 88.4% average confidence
- **ğŸ“ Output Quality**: 76,800-point 3D models in OBJ/PLY formats

## ğŸ—ï¸ Four-Stage Processing Pipeline

### Stage 0: Setup and Data Foundation
- **CoppeliaSim Setup**: Complete simulation environment
- **Synthetic Dataset**: 500+ RGB-D images across 25+ scenes
- **Ground Truth Data**: Sub-millimeter precision validation
- **Camera Integration**: RGB-D capture and processing

### Stage 1: 2D Instance Segmentation
- **Technology**: Custom-trained YOLOv8 neural network
- **Input**: RGB color images
- **Output**: Precise pixel-level masks for object isolation
- **Training**: Complete dataset with model weights

### Stage 2: 3D Point Cloud Generation
- **Technology**: RGB-D fusion with pinhole camera model
- **Input**: 2D masks + corresponding depth maps
- **Output**: Dense, colored 3D point clouds (76,800+ points)
- **Process**: Back-projection using camera intrinsic parameters

### Stage 3: 6D Pose Extraction
- **Position**: Calculated via centroid of all points
- **Orientation**: Extracted using Principal Component Analysis (PCA)
- **Output**: Complete 6D pose (x, y, z, roll, pitch, yaw)
- **Processing**: Real-time pose estimation

### Stage 4: Output Formatting
- **Format**: 3x3 Rotation Matrix â†’ Euler Angles
- **Output**: Industry-standard 6D pose ready for robotic applications
- **Models**: High-quality OBJ/PLY 3D models
- **Integration**: Compatible with robotic frameworks

## ğŸ”¬ Technical Implementation

- **Framework**: Python with PyTorch + Metal Performance Shaders
- **Hardware**: Apple Silicon GPU acceleration
- **Simulator**: CoppeliaSim robotics simulator
- **Dataset**: 500+ RGB-D images across 25+ scenes
- **Annotation**: Roboflow for precise ground truth labeling

## ğŸ“ Project Structure

```
multi_model_pose_recognition/
â”œâ”€â”€ 00_setup_and_data/           # CoppeliaSim setup & synthetic dataset
â”œâ”€â”€ 01_stage_2d_instance_segmentation/  # YOLOv8 training & RGB processing
â”œâ”€â”€ 02_stage_3d_point_cloud_generation/ # Depth processing & back-projection
â”œâ”€â”€ 03_stage_6d_pose_extraction/        # PCA orientation & centroid computation
â”œâ”€â”€ 04_stage_output_formatting/         # Euler angles & 3D model generation
â”œâ”€â”€ 06_documentation/                   # Technical specs & user guides
â””â”€â”€ 07_utilities/                       # Utility tools and helpers
```

## ğŸš€ Getting Started

1. **Install Dependencies**: `pip install -r requirements.txt`
2. **Setup CoppeliaSim**: Follow setup guide in `00_setup_and_data/`
3. **Train YOLOv8 Model**: Use scripts in `01_stage_2d_instance_segmentation/`
4. **Run Pipeline**: Execute main processing scripts in order

## ğŸ“ Research Contributions

1. **Novel Architecture**: Integration of deep learning (YOLOv8) with geometric CV (PCA)
2. **Performance Breakthrough**: Achieves both real-time speed AND high accuracy
3. **Industrial Ready**: Directly addresses the speed vs. accuracy research gap
4. **Modular Design**: Each stage can be independently optimized and replaced

## ğŸ”® Future Work

- **Sim-to-Real Validation**: Adapt system for physical hardware
- **Multi-Object Scenarios**: Extend to handle multiple objects simultaneously
- **Dynamic Environments**: Test in real-world manufacturing conditions

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Deepak Ananthapadman** - Multi-Modal AI 6D Pose Recognition Research Project

---

*This system represents a significant advancement in robotic manipulation, providing the foundation for next-generation industrial automation systems.*